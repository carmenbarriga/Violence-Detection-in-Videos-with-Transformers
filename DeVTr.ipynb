{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1SBUgc19KMWSqh/T/eldR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "702d5c1ac12045ec8568cdfc5bf238bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5b6769fa51b459eb170390bc806e395",
              "IPY_MODEL_a520dc21f85e49468f26e8436ec4e718",
              "IPY_MODEL_d99546f8c14e48999cc4d96f9feddc68"
            ],
            "layout": "IPY_MODEL_8b1faf16d05341879fa594e032949498"
          }
        },
        "e5b6769fa51b459eb170390bc806e395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69892358ed724fd1aca746fc853f1324",
            "placeholder": "​",
            "style": "IPY_MODEL_adcef1f50a7b4e9d8e00b50cf6252806",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "a520dc21f85e49468f26e8436ec4e718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07795a11bf074a68a9c566f3ef7673c5",
            "max": 574767384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_556bbfadba304769adc2363e736ecee4",
            "value": 574767384
          }
        },
        "d99546f8c14e48999cc4d96f9feddc68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_512a00ab24d546aba4df172602333bcf",
            "placeholder": "​",
            "style": "IPY_MODEL_379db7401fcd4887969686ecbc0c8773",
            "value": " 575M/575M [00:04&lt;00:00, 150MB/s]"
          }
        },
        "8b1faf16d05341879fa594e032949498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69892358ed724fd1aca746fc853f1324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adcef1f50a7b4e9d8e00b50cf6252806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07795a11bf074a68a9c566f3ef7673c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "556bbfadba304769adc2363e736ecee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "512a00ab24d546aba4df172602333bcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "379db7401fcd4887969686ecbc0c8773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e370930d27b4b7096c070cd6ceec2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5c0ffbbf385401997848cf59f225f6d",
              "IPY_MODEL_5b9f82b0fc584e8fba37ef2ff89234be",
              "IPY_MODEL_eb0eee6f529d462bb00666c30c09df12"
            ],
            "layout": "IPY_MODEL_9b323f054bf249269dc27dcbdb330d6e"
          }
        },
        "d5c0ffbbf385401997848cf59f225f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_720e50dd165641c9af0974ec1def32d2",
            "placeholder": "​",
            "style": "IPY_MODEL_56ef482e0f7843a3ba672f5d784104a6",
            "value": "100%"
          }
        },
        "5b9f82b0fc584e8fba37ef2ff89234be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9f23e0ab11645dab19114f367497240",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1684b36d26143499b8f86b024a5a0c7",
            "value": 25
          }
        },
        "eb0eee6f529d462bb00666c30c09df12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b41812dfbf6411f8230508a7770b883",
            "placeholder": "​",
            "style": "IPY_MODEL_1e6d8481a2644c22bdceb5596232db0a",
            "value": " 25/25 [11:11&lt;00:00, 24.72s/it, loss=0.102]"
          }
        },
        "9b323f054bf249269dc27dcbdb330d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "720e50dd165641c9af0974ec1def32d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ef482e0f7843a3ba672f5d784104a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9f23e0ab11645dab19114f367497240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1684b36d26143499b8f86b024a5a0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b41812dfbf6411f8230508a7770b883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e6d8481a2644c22bdceb5596232db0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carmenbarriga/Violence-Detection-in-Videos-with-Transformers/blob/main/DeVTr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Efficient Video Transformer - DeVTr**\n",
        "\n",
        "@inproceedings{abdali2021data,\n",
        "  title={Data efficient video transformer for violence detection},\n",
        "  author={Abdali, Almamon Rasool},\n",
        "  booktitle={2021 IEEE International Conference on Communication, Networks and Satellite (COMNETSAT)},\n",
        "  pages={195--199},\n",
        "  year={2021},\n",
        "  organization={IEEE}\n",
        "}"
      ],
      "metadata": {
        "id": "xmWbYdxzN4AK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.- Installation of the necessary libraries**\n",
        "\n",
        "*   **Menovideo:** PyTorch library where DeVTr can be used\n",
        "*   **Timm:** Library that provides pre-trained implementations of deep learning models using the PyTorch framework\n"
      ],
      "metadata": {
        "id": "bnrZyHzUOkRz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA0EmixS-GRU",
        "outputId": "9b782ec7-9ae1-42f3-a7f9-e4e5bf120a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting menovideo\n",
            "  Downloading menovideo-0.5.1-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from menovideo) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from menovideo) (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->menovideo) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->menovideo) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->menovideo) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->menovideo) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->menovideo) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->menovideo) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->menovideo) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->menovideo) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->menovideo) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->menovideo) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->menovideo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->menovideo) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->menovideo) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->menovideo) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->menovideo) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->menovideo) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->menovideo) (1.3.0)\n",
            "Installing collected packages: menovideo\n",
            "Successfully installed menovideo-0.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.14.1 safetensors-0.3.1 timm-0.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install menovideo\n",
        "!pip install timm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.- Mount Google Drive**\n",
        "Mount Google Drive to be able to access Google Drive files and directories"
      ],
      "metadata": {
        "id": "IYuX3rnsPaW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj7fFv9-Euia",
        "outputId": "d93ee31b-30f1-478d-b10c-b5468821272f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.- Import the necessary libraries**"
      ],
      "metadata": {
        "id": "-tpgSNU5P8d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import torch\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import menovideo.menovideo as menoformer\n",
        "import menovideo.videopre as vide_reader"
      ],
      "metadata": {
        "id": "B3j1112C-uZr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.- Make some configurations**\n",
        "The function `seed_everything` is used to set seeds across various libraries and environments in Python to ensure reproducibility of results. Seed 1001 will be used."
      ],
      "metadata": {
        "id": "Cy-l3UnY8alU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "  # Sets the seed for the torch library's random number generator (PyTorch) for both the CPU and GPU\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  # To ensure that calculations performed with the torch library on the GPU are deterministic\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  # Turn off automatic benchmarking and default settings are used to ensure more stable and predictable execution\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(1001)"
      ],
      "metadata": {
        "id": "IeKxt6iF7Juj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Releases the GPU cache used by PyTorch and displays the current Pytorch version"
      ],
      "metadata": {
        "id": "z7DSZswPDzRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "s_nAALmD7lJF",
        "outputId": "b528cad0-1199-4ee8-88d5-a9fdd93a5aee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To determine on which device the PyTorch computations will be executed, either on a GPU (CUDA) or on the CPU"
      ],
      "metadata": {
        "id": "nSdIStRHEBHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lmd-QBHs5cQR",
        "outputId": "0942a9fe-e113-47d1-93e9-aa93b0d02270"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.- Prepare the database**"
      ],
      "metadata": {
        "id": "MpVSFVrY9kJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set database folder paths:\n",
        "* RLVS\n",
        "* Hockey Fight\n",
        "* Violence in Movies\n",
        "* RWF-2000\n",
        "\n"
      ],
      "metadata": {
        "id": "xSm62WRF-7ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RLVS\n",
        "rlvs_folder = '/content/drive/MyDrive/transformers-for-violence-detection-in-videos/Datasets/real-life-violence-situations-dataset/Real Life Violence Dataset/'\n",
        "# Hockey Fight\n",
        "hockey_fight_folder = '/content/drive/MyDrive/transformers-for-violence-detection-in-videos/Datasets/hockey-fight-dataset/'\n",
        "# Violence in Movies\n",
        "violence_in_movies_folder = '/content/drive/MyDrive/transformers-for-violence-detection-in-videos/Datasets/violence-in-movies-dataset/'\n",
        "# RWF-2000\n",
        "# rwf_2000_folder = ''"
      ],
      "metadata": {
        "id": "A_b-4gM59_Ob"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to check that videos can be opened correctly"
      ],
      "metadata": {
        "id": "34oPID9D_ipk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_frames(video_dir, min_frames=25):\n",
        "  number_of_frames = 0\n",
        "  video = cv2.VideoCapture(video_dir)\n",
        "  if video.isOpened():\n",
        "    while number_of_frames < min_frames:\n",
        "      is_frame_read, frame = video.read()\n",
        "      if frame is None:\n",
        "        print(f\"Something went wrong with '{video_dir}' video\")\n",
        "        return False\n",
        "      number_of_frames += 1\n",
        "  else:\n",
        "    print(f\"Can't open '{video_dir}'\")\n",
        "    return False\n",
        "\n",
        "  return True"
      ],
      "metadata": {
        "id": "MSPIRulcAMFb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to get the paths where videos are located and their labels"
      ],
      "metadata": {
        "id": "-7bV3KkHAZSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_labels(main_dir):\n",
        "  videos = []\n",
        "  labels = []\n",
        "  for folder_name in os.listdir(main_dir):\n",
        "    folder_dir = main_dir + folder_name + '/'\n",
        "    print(f'Folder name: {folder_name}\\nFolder dir: {folder_dir}')\n",
        "    for file_name in os.listdir(folder_dir):\n",
        "      file_dir = folder_dir + file_name\n",
        "      if check_frames(file_dir):\n",
        "        video_dir = os.path.join(folder_dir, file_name)\n",
        "        videos.append(video_dir)\n",
        "        if folder_name == 'Violence':\n",
        "          labels.append(1)\n",
        "        else:\n",
        "          labels.append(0)\n",
        "  return videos, labels"
      ],
      "metadata": {
        "id": "H8wWeKh87yAl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the dataframe"
      ],
      "metadata": {
        "id": "f_CIonbdVcX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "videos, labels = get_video_labels(rlvs_folder)\n",
        "data = pd.DataFrame(data={\"file\": videos, \"label\": labels})\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "hxRnOZG8Bz0G",
        "outputId": "ecec6dce-d526-4734-e91a-f2918095e3a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder name: Violence\n",
            "Folder dir: /content/drive/MyDrive/transformers-for-violence-detection-in-videos/Datasets/real-life-violence-situations-dataset/Real Life Violence Dataset/Violence/\n",
            "Folder name: NonViolence\n",
            "Folder dir: /content/drive/MyDrive/transformers-for-violence-detection-in-videos/Datasets/real-life-violence-situations-dataset/Real Life Violence Dataset/NonViolence/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                file  label\n",
              "0  /content/drive/MyDrive/transformers-for-violen...      1\n",
              "1  /content/drive/MyDrive/transformers-for-violen...      1\n",
              "2  /content/drive/MyDrive/transformers-for-violen...      1\n",
              "3  /content/drive/MyDrive/transformers-for-violen...      1\n",
              "4  /content/drive/MyDrive/transformers-for-violen...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff0e5760-cd9d-4994-a4cd-51a29e00fbfe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/transformers-for-violen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/transformers-for-violen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/transformers-for-violen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/transformers-for-violen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/transformers-for-violen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff0e5760-cd9d-4994-a4cd-51a29e00fbfe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff0e5760-cd9d-4994-a4cd-51a29e00fbfe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff0e5760-cd9d-4994-a4cd-51a29e00fbfe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data for training and testing:\n",
        "*   80% train\n",
        "*   20% test\n",
        "\n"
      ],
      "metadata": {
        "id": "d0h0i0SPYI2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = model_selection.train_test_split(\n",
        "  data, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "nCvz0G5s0JnX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show train data information"
      ],
      "metadata": {
        "id": "PrA3OLROEdAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train data shape: ', train_data.shape)\n",
        "print('Number of violence videos in train data: ', train_data['label'].value_counts()[1])\n",
        "print('Number of non violence videos in train data: ', train_data['label'].value_counts()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k-vmKn60usn",
        "outputId": "7f179251-bc64-4fbe-80f4-60af8f8c9dc4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape:  (1600, 2)\n",
            "Number of violence videos in train data:  801\n",
            "Number of non violence videos in train data:  799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show test data information"
      ],
      "metadata": {
        "id": "YHGWmbTBE43i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test data shape: ', test_data.shape)\n",
        "print('Number of violence videos in test data: ', test_data['label'].value_counts()[1])\n",
        "print('Number of non violence videos in test data: ', test_data['label'].value_counts()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suQ6Ji2r0yc9",
        "outputId": "a1b8da00-5fc3-4d52-aedc-1edc65af24c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data shape:  (400, 2)\n",
            "Number of violence videos in test data:  199\n",
            "Number of non violence videos in test data:  201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`vide_reader.TaskDataset` parameters:\n",
        "1. Pandas dataframe contain the path and label of each video\n",
        "2. `timesep`: Number of frames of a video\n",
        "3. `rgb`: Number of color channels\n",
        "4. `h`: Height of each frame\n",
        "5. `w`: Width of each frame\n"
      ],
      "metadata": {
        "id": "dsv1fE0IEiz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_stp = 40\n",
        "RGB = 3\n",
        "H = 200\n",
        "W = 200\n",
        "test_dataset = vide_reader.TaskDataset(test_data, timesep=time_stp, rgb=RGB, h=H, w=W)"
      ],
      "metadata": {
        "id": "84q4eUox7qVX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To realease the memory because data, train_data and test_data are no longer needed"
      ],
      "metadata": {
        "id": "MvWDcrH3g1IW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del data\n",
        "del train_data\n",
        "del test_data"
      ],
      "metadata": {
        "id": "VyWUAgVl3O2P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "sjefz4IQjrBr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataLoader to load the test dataset in batches during model evaluation"
      ],
      "metadata": {
        "id": "3l6OAcvRjwSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(\n",
        "  dataset=test_dataset,\n",
        "  # Sets the batch size, that is, how many examples will be loaded simultaneously in each iteration\n",
        "  batch_size=BATCH_SIZE,\n",
        "  # The data must be copied to a \"fixed\" region of memory on the GPU device.\n",
        "  # This means that data will be copied from RAM to GPU memory before training begins\n",
        "  pin_memory=True,\n",
        "  # If the total number of examples is not divisible by the batch size,\n",
        "  # the last few examples will be skipped\n",
        "  drop_last=True,\n",
        "  # Specifies to 0 the number of worker threads to use to load the data in parallel to memory\n",
        "  num_workers=0,\n",
        "  # The data will be kept in its original order at each evaluation epoch\n",
        "  shuffle=False,\n",
        ")\n",
        "dataloaders = {'test': test_loader}\n",
        "dataset_sizes = {'test': len(test_dataset)}\n",
        "print(dataloaders)\n",
        "print(dataset_sizes)"
      ],
      "metadata": {
        "id": "vJ8u5zqg3Z4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e5b8b5-3e05-484b-a380-cccb23c1df63"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'test': <torch.utils.data.dataloader.DataLoader object at 0x7f0880b8f370>}\n",
            "{'test': 400}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.- Instantiate the model and specify the necessary parameters**\n",
        "\n",
        "### **Model Architecture**\n",
        "\n",
        "#### **Embedding Network**\n",
        "1. Pre-trained 2D-CNN: Batch normalized VGG-19\n",
        "2. Feed Forward Neural Network\n",
        "\n",
        "#### **Transformer Encoder**\n",
        "\n",
        "#### **Classification Network**\n",
        "Two layers:\n",
        "1.   Feed Forward Neural Network with 1024 neurons, 40% of dropout and RELU as activation function.\n",
        "2.   Feed Forward Neural Network with a single neuron with sigmoid function to make a binary classification.\n",
        "\n",
        "#### **Model Parameters**\n",
        "*   **w:** The path for pre-traied DeVTr model\n",
        "*   **base:** The base CNN that works as input embedding layer. If set to default it will use paper default work with VGG-19\n",
        "*   **classifier:** The classifier Deep Neural Network (DNN) that recive the output from the Transformer encoder. If set to default it will use the same architecture of the paper. If it is wanted to use another architecture, it is needed to pass to it. Any nn.sequential network will work.\n",
        "*   **mid_layer:** Feed Forward Network which is placed directly after the output of the Transformer encoder\n",
        "*   **mid_drop:** Dropout for the mid_layer\n",
        "*   **num_class:** Number of the output classes\n",
        "*   **dim_embd:** Dimensionalty that we want our input to be after   transformed by time distrpyted ConvNet\n",
        "*   **dr_rate:** Dropout of the Transformer encoder\n",
        "*   **time_stp:** Number of frames of the input \n",
        "\n",
        "## **Default values**\n",
        "  ```\n",
        "  menoformer.DeVTr(\n",
        "    w='none',\n",
        "    base='default',\n",
        "    classifier='default',\n",
        "    mid_layer=1024,\n",
        "    mid_drop=0.4,\n",
        "    num_classes=1,\n",
        "    dim_embd=512,\n",
        "    dr_rate=0.1,\n",
        "    time_stp=40,\n",
        "  )\n",
        "  ```\n"
      ],
      "metadata": {
        "id": "Vy8yAcTFQPQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = 'drive/MyDrive/transformers-for-violence-detection-in-videos/vg19bn40convtransformer-ep-0.pth'\n",
        "model = menoformer.DeVTr(w=weights, base='default')\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "702d5c1ac12045ec8568cdfc5bf238bc",
            "e5b6769fa51b459eb170390bc806e395",
            "a520dc21f85e49468f26e8436ec4e718",
            "d99546f8c14e48999cc4d96f9feddc68",
            "8b1faf16d05341879fa594e032949498",
            "69892358ed724fd1aca746fc853f1324",
            "adcef1f50a7b4e9d8e00b50cf6252806",
            "07795a11bf074a68a9c566f3ef7673c5",
            "556bbfadba304769adc2363e736ecee4",
            "512a00ab24d546aba4df172602333bcf",
            "379db7401fcd4887969686ecbc0c8773"
          ]
        },
        "id": "IK81Ose05G4N",
        "outputId": "6e3c473a-e0e1-47f3-b0f7-0a76eb4b0379"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/575M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "702d5c1ac12045ec8568cdfc5bf238bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): TimeWarp(\n",
              "    (baseModel): Sequential(\n",
              "      (0): VGG(\n",
              "        (features): Sequential(\n",
              "          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "          (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "          (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (9): ReLU(inplace=True)\n",
              "          (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (12): ReLU(inplace=True)\n",
              "          (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "          (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (16): ReLU(inplace=True)\n",
              "          (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (19): ReLU(inplace=True)\n",
              "          (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (22): ReLU(inplace=True)\n",
              "          (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (25): ReLU(inplace=True)\n",
              "          (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "          (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (29): ReLU(inplace=True)\n",
              "          (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (32): ReLU(inplace=True)\n",
              "          (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (35): ReLU(inplace=True)\n",
              "          (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (38): ReLU(inplace=True)\n",
              "          (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "          (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (42): ReLU(inplace=True)\n",
              "          (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (45): ReLU(inplace=True)\n",
              "          (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (48): ReLU(inplace=True)\n",
              "          (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (51): ReLU(inplace=True)\n",
              "          (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        )\n",
              "        (pre_logits): ConvMlp(\n",
              "          (fc1): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "          (fc2): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act2): ReLU(inplace=True)\n",
              "        )\n",
              "        (head): ClassifierHead(\n",
              "          (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "          (fc): Linear(in_features=4096, out_features=512, bias=True)\n",
              "          (flatten): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (1): PostionalEcnoder(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (2): memoTransormer(\n",
              "    (encoder_layer): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer_encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-3): 4 x TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (3): Flatten(start_dim=1, end_dim=-1)\n",
              "  (4): Linear(in_features=20480, out_features=1024, bias=True)\n",
              "  (5): Dropout(p=0.4, inplace=False)\n",
              "  (6): ReLU()\n",
              "  (7): Linear(in_features=1024, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, criterion, device='cuda'):\n",
        "  model.to(device)\n",
        "\n",
        "  # To start the evaluation time\n",
        "  since = time.time()\n",
        "  model.eval()\n",
        "  total_loss_sum = 0.0\n",
        "  correct_predictions_counter = 0\n",
        "  pred_vs_real = {}\n",
        "  pred_vs_real['pred']= []\n",
        "  pred_vs_real['real']= []\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  # To create a progress bar to iterate over the 'test' dataloader using the tqdm library\n",
        "  progress_bar = tqdm(dataloaders['test'], total=int(len(dataloaders['test'])))\n",
        "\n",
        "  processed_batch_counter = 0\n",
        "  for batch, sample in enumerate(progress_bar):\n",
        "    # Get the videos and labels from the data batch and move them to the corresponding device memory\n",
        "    inputs = sample['video'].to(device , dtype=torch.float)   # [16, 40, 3, 200, 200]\n",
        "    labels = sample['label'].view(sample['label'].shape[0], 1)  # [16] -> [16, 1]\n",
        "    labels = labels.to(device, dtype=torch.float)\n",
        "\n",
        "    # Get the outputs predicted by the model\n",
        "    outputs = model(inputs)\n",
        "    # Apply a sigmoid activation function to the outputs to obtain the predictions\n",
        "    # and round the predictions to be binary (0 or 1)\n",
        "    preds = torch.round(torch.sigmoid(outputs))\n",
        "\n",
        "    # Add the predictions and labels to the dictionary pred_vs_real\n",
        "    # converted to a numpy array and move them to CPU memory\n",
        "    pred_vs_real['pred'].extend(preds.cpu().detach().numpy().flatten())\n",
        "    pred_vs_real['real'].extend(labels.cpu().detach().numpy().flatten())\n",
        "\n",
        "    # Calculate the loss with the function specified in the criterion variable\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Statistics\n",
        "    processed_batch_counter += 1\n",
        "    # To get the total loss of the current batch:\n",
        "    #   - loss.item() is the scalar value of the current batch loss\n",
        "    #   - inputs.size(0) gets the batch size\n",
        "    total_loss_sum += loss.item() * inputs.size(0)\n",
        "    # Adds the number of correct predictions in the current batch to the accumulated correct predictions counter\n",
        "    correct_predictions_counter += torch.sum(preds == labels.data)\n",
        "\n",
        "    # Updates the progress message in the progress_bar iterator showing the average loss\n",
        "    # To do this, divide the accumulated loss by the total number of samples processed so far\n",
        "    progress_bar.set_postfix(loss=(total_loss_sum / (processed_batch_counter * dataloaders['test'].batch_size)))\n",
        "\n",
        "  final_loss = total_loss_sum / dataset_sizes['test']\n",
        "  accuracy = correct_predictions_counter.double() / dataset_sizes['test']\n",
        "  precision = precision_score(pred_vs_real['real'], pred_vs_real['pred'])\n",
        "  recall = recall_score(pred_vs_real['real'], pred_vs_real['pred'])\n",
        "  print('{} Loss: {:.4f} Accuracy: {:.4f} Precision: {:.4f} Recall: {:.4f}'.format('test', final_loss, accuracy, precision, recall))\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print('testing complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "  return pred_vs_real"
      ],
      "metadata": {
        "id": "epT7a3JTa9uW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the loss function**\n",
        "\n",
        "`BCEWithLogitsLoss` is the **Binary Cross Entropy with Logits Loss** used for binary classification tasks.\n",
        "\n",
        "The `BCEWithLogitsLoss` function combines the sigmoid activation function and the cross entropy loss in a single operation. In this case, each sample can belong to one of two classes, represented by the labels $0$ (Nonviolence) and $1$ (Violence). We denote model predictions as logits (i.e., the raw outputs of the model before applying an activation function) and true labels as $y$.\n",
        "\n",
        "*   Application of the sigmoid function:\n",
        "\n",
        "$$\n",
        "\\text{logits_sigmoid} = sigmoid(\\text{logits})\n",
        "$$\n",
        "\n",
        "Where $sigmoid$ is the sigmoid activation function which transforms the logits into probabilities between $0$ and $1$.\n",
        "*   Calculation of cross entropy loss:\n",
        "\n",
        "$$\n",
        "\\text{loss} = - (y \\cdot \\log(\\text{logits_sigmoid}) + (1 - y) \\cdot \\log(1 - \\text{logits_sigmoid}))\n",
        "$$\n",
        "\n",
        "Where $\\log$ is the logarithm function.\n",
        "\n",
        "The above formula calculates the binary cross entropy loss for each sample individually. The average of all the samples is then taken to obtain the total loss.\n"
      ],
      "metadata": {
        "id": "3rGS47xs4Zr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "4HyjGLKL4YtY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rl_vs_prd = test_model(model, criterion, device)\n",
        "print(rl_vs_prd)"
      ],
      "metadata": {
        "id": "NE7-Q1YX4n2X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "7e370930d27b4b7096c070cd6ceec2ec",
            "d5c0ffbbf385401997848cf59f225f6d",
            "5b9f82b0fc584e8fba37ef2ff89234be",
            "eb0eee6f529d462bb00666c30c09df12",
            "9b323f054bf249269dc27dcbdb330d6e",
            "720e50dd165641c9af0974ec1def32d2",
            "56ef482e0f7843a3ba672f5d784104a6",
            "f9f23e0ab11645dab19114f367497240",
            "d1684b36d26143499b8f86b024a5a0c7",
            "7b41812dfbf6411f8230508a7770b883",
            "1e6d8481a2644c22bdceb5596232db0a"
          ]
        },
        "outputId": "84b82fce-b565-42d6-ead8-b5080882c1fd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e370930d27b4b7096c070cd6ceec2ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test Loss: 0.1022 Accuracy: 0.9625 Precision: 0.9742 Recall: 0.9497\n",
            "testing complete in 11m 12s\n",
            "{'pred': [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], 'real': [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rl_vs_prd['pred'])\n",
        "print(rl_vs_prd['real'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hERHkgGZagqz",
        "outputId": "57da81d7-cab8-4c46-998a-164616752d99"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]\n",
            "[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]\n"
          ]
        }
      ]
    }
  ]
}